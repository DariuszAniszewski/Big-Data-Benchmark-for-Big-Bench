#!/usr/bin/env bash

execclusterDataGen () {
	if grep -q "IS_EULA_ACCEPTED=true" "$BIG_BENCH_DATA_GENERATOR_DIR/Constants.properties"; then
		echo "EULA is accepted"
	else
		echo "==============================================="
		echo "data generator EULA"
		echo "==============================================="
		echo "This is your first run of the data generation tool. Please accept the EULA."
		java -jar "$BIG_BENCH_DATA_GENERATOR_DIR"/pdgf.jar -ns -c
		if grep -q "IS_EULA_ACCEPTED=true" "$BIG_BENCH_DATA_GENERATOR_DIR/Constants.properties"; then
			echo "OK"
		else
			echo "ERROR! data generation tool EULA is not accepted. Cannot procced"
			return 1 
		fi
	fi

	if [ -n "$SCALE_FACTOR" ]
	then
		local PDGF_OPTIONS="-sf $SCALE_FACTOR"
	fi

	local CLUSTER_CONF=" -Dcore-site.xml=${BIG_BENCH_DATAGEN_CORE_SITE} -Dhdfs-site.xml=${BIG_BENCH_DATAGEN_HDFS_SITE} -Djava.library.path=${BIG_BENCH_HADOOP_LIBS_NATIVE} -DFileChannelProvider=pdgf.util.caching.fileWriter.HDFSChannelProvider -Ddfs.replication.override=${BIG_BENCH_DATAGEN_DFS_REPLICATION} "
	#echo $CLUSTER_CONF

	local IPs=(${BIG_BENCH_NODES})
	local NODE_COUNT=${#IPs[@]}

	echo "==============================================="
	echo "Deleting any previously generated data, results and logs."
	echo "==============================================="
	"${BIG_BENCH_BASH_SCRIPT_DIR}/bigBench" cleanData
	echo "OK"
	echo "==============================================="
	echo "make hdfs benchmark data dir: "${BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR}
	echo "==============================================="
	hadoop fs -mkdir -p "${BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR}"
	rc=$?
	if [[ $rc != 0 ]] ; then
    		echo "Error creating hdfs dir: ${BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR}"
    		return $rc
	fi

	hadoop fs -chmod -R 777 "${BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR}"
	rc=$?
	if [[ $rc != 0 ]] ; then
    		echo "Error setting permission for hdfs dir: ${BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR}"
    		return $rc
	fi

	hadoop fs -ls "${BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR}"

	echo "OK"
	echo "==============================================="
	echo "make hdfs benchmark data dir: "${BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR}
	echo "==============================================="
	hadoop fs -mkdir -p "${BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR}"
	rc=$?
	if [[ $rc != 0 ]] ; then
    		echo "Error creating hdfs dir: ${BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR}"
    		return $rc
	fi

	hadoop fs -chmod -R 777 "${BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR}"
	rc=$?
	if [[ $rc != 0 ]] ; then
    		echo "Error setting permission for hdfs dir: ${BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR}"
    		return $rc
	fi

	hadoop fs -ls "${BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR}"
	echo "OK"

	echo "==============================================="
	echo "Starting data generation job."
	echo "==============================================="
	local HADOOP_CP=`hadoop classpath`
	echo "HADOOP CLASSPATH: $HADOOP_CP"

	for (( i = 0; i < ${NODE_COUNT}; i++ ));
	do
		echo ssh ${BIG_BENCH_SSH_OPTIONS} ${IPs[$i]} java ${BIG_BENCH_DATAGEN_JVM_ENV} -cp "${HADOOP_CP}:${BIG_BENCH_DATA_GENERATOR_DIR}/pdgf.jar" ${CLUSTER_CONF} pdgf.Controller -nc ${NODE_COUNT} -nn $((i+1)) -ns -c -sp REFRESH_PHASE 0 -o "'${BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR}/'+table.getName()+'/'" -s ${BIGBENCH_TABLES} ${PDGF_OPTIONS} "$@"
		ssh ${BIG_BENCH_SSH_OPTIONS} ${IPs[$i]} java ${BIG_BENCH_DATAGEN_JVM_ENV} -cp "${HADOOP_CP}:${BIG_BENCH_DATA_GENERATOR_DIR}/pdgf.jar" ${CLUSTER_CONF} pdgf.Controller -nc ${NODE_COUNT} -nn $((i+1)) -ns -c -sp REFRESH_PHASE 0 -o "\'${BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR}/\'+table.getName\(\)+\'/\'" -s ${BIGBENCH_TABLES} ${PDGF_OPTIONS} "$@" &
		echo ssh ${BIG_BENCH_SSH_OPTIONS} ${IPs[$i]} java ${BIG_BENCH_DATAGEN_JVM_ENV} -cp "${HADOOP_CP}:${BIG_BENCH_DATA_GENERATOR_DIR}/pdgf.jar" ${CLUSTER_CONF} pdgf.Controller -nc ${NODE_COUNT} -nn $((i+1)) -ns -c -sp REFRESH_PHASE 1 -o "'${BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR}/'+table.getName()+'/'" -s ${BIGBENCH_TABLES} ${PDGF_OPTIONS} "$@"
		ssh ${BIG_BENCH_SSH_OPTIONS} ${IPs[$i]} java ${BIG_BENCH_DATAGEN_JVM_ENV} -cp "${HADOOP_CP}:${BIG_BENCH_DATA_GENERATOR_DIR}/pdgf.jar" ${CLUSTER_CONF} pdgf.Controller -nc ${NODE_COUNT} -nn $((i+1)) -ns -c -sp REFRESH_PHASE 1 -o "\'${BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR}/\'+table.getName\(\)+\'/\'" -s ${BIGBENCH_TABLES} ${PDGF_OPTIONS} "$@" &
	done
	wait
	echo "==============================================="
	echo "SSH cluster data generation job finished. "
	echo "View generated initial files: hadoop fs -ls ${BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR}"
	echo "View generated refresh files: hadoop fs -ls ${BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR}"
	echo "==============================================="
}
