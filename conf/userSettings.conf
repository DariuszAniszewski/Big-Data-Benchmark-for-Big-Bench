#!/usr/bin/env bash

## ==========================
## JAVA environment
## ==========================
<<<<<<< HEAD
export BIG_BENCH_JAVA="java"
=======
export BIG_BENCH_JAVA=/usr/java/default/bin/java
>>>>>>> parent of 0ac0dd4... Minor change to java environment variable

## ==========================
## default settings for benchmark
## ==========================
export BIG_BENCH_DEFAULT_DATABASE="bigbenchORC"
export BIG_BENCH_DEFAULT_ENGINE="hive"
export BIG_BENCH_DEFAULT_MAP_TASKS="80"
export BIG_BENCH_DEFAULT_SCALE_FACTOR="10"
export BIG_BENCH_DEFAULT_NUMBER_OF_PARALLEL_STREAMS="2"
export BIG_BENCH_DEFAULT_BENCHMARK_PHASE="RUN_QUERY"
export BIG_BENCH_DEFAULT_STREAM_NUMBER="0"

## ==========================
## HADOOP environment
## ==========================

##folder containing the cluster setup *-site.xml files like core-site.xml
export BIG_BENCH_HADOOP_CONF="/etc/hadoop/conf.cloudera.hdfs" 
export BIG_BENCH_HADOOP_LIBS_NATIVE="/opt/cloudera/parcels/CDH/lib/hadoop/lib/native"

## memory used by sub-processes spawned by Hive queries (like streaming M/R jobs etc.)
## Suggestion for value: (YarnConatiner_MB - hive_MB)*0.7 e.g. (2000Mb-500Mb)*0.7=1050
export BIG_BENCH_java_child_process_xmx=" -Xmx1024m "

## ==========================
## HDFS config and paths
## ==========================
export BIG_BENCH_USER="$USER"
export BIG_BENCH_HDFS_ABSOLUTE_PATH="/user/$BIG_BENCH_USER" ##working dir of benchmark.
export BIG_BENCH_HDFS_RELATIVE_INIT_DATA_DIR="benchmarks/bigbench/data"
export BIG_BENCH_HDFS_RELATIVE_REFRESH_DATA_DIR="benchmarks/bigbench/data_refresh"
export BIG_BENCH_HDFS_RELATIVE_QUERY_RESULT_DIR="benchmarks/bigbench/queryResults"
export BIG_BENCH_HDFS_RELATIVE_TEMP_DIR="benchmarks/bigbench/temp"
export BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR="$BIG_BENCH_HDFS_ABSOLUTE_PATH/$BIG_BENCH_HDFS_RELATIVE_INIT_DATA_DIR"
export BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR="$BIG_BENCH_HDFS_ABSOLUTE_PATH/$BIG_BENCH_HDFS_RELATIVE_REFRESH_DATA_DIR"
export BIG_BENCH_HDFS_ABSOLUTE_QUERY_RESULT_DIR="$BIG_BENCH_HDFS_ABSOLUTE_PATH/$BIG_BENCH_HDFS_RELATIVE_QUERY_RESULT_DIR"
export BIG_BENCH_HDFS_ABSOLUTE_TEMP_DIR="$BIG_BENCH_HDFS_ABSOLUTE_PATH/$BIG_BENCH_HDFS_RELATIVE_TEMP_DIR"

# --------------------------------------------
# Hadoop data generation options
# --------------------------------------------
# specify JVM arguments like: -Xmx2000m; 
# default of: 300m is sufficient if the datagen only uses 1 worker thread per map task
# Add +100MB per addition worker if you modified: BIG_BENCH_DATAGEN_HADOOP_OPTIONS
export BIG_BENCH_DATAGEN_HADOOP_JVM_ENV="$BIG_BENCH_JAVA -DDEBUG_PRINT_PERIODIC_THREAD_DUMPS=5000 -Xmx300m "

# if you increase -workers, you must also increase the -Xmx setting in BIG_BENCH_DATAGEN_HADOOP_JVM_ENV;
#-ap:=automatic progress ,3000ms intervall; prevents hadoop from killing long running jobs
#-workers:=limit hadoop based data generator to use 1 CPU core per map task.
export BIG_BENCH_DATAGEN_HADOOP_OPTIONS=" -workers 1 -ap 3000 "

#(recommended:1) replication count for files written by the datagenerator to HDFS into dir: BIG_BENCH_HDFS_ABSOLUTE_INIT_DATA_DIR and BIG_BENCH_HDFS_ABSOLUTE_REFRESH_DATA_DIR
export BIG_BENCH_DATAGEN_DFS_REPLICATION="1"

# if empty, generate all tables.
# Else: specify tables to generate e.g.: BIG_BENCH_DATAGEN_TABLES="item customer store"
# Tables to choose from: customer customer_address customer_demographics date_dim household_demographics income_band inventory item item_marketprices product_reviews promotion reason ship_mode store store_returns store_sales time_dim warehouse web_clickstreams web_page  web_returns web_sales web_site
export BIG_BENCH_DATAGEN_TABLES=""

# if distributed data generation fails, re run with BIG_BENCH_DATAGEN_HADOOP_EXEC_DEBUG="-testDebugMessages" to retrieve more information.
export BIG_BENCH_DATAGEN_HADOOP_EXEC_DEBUG=""

# the default behaviour is to keep on running when a query error occurs
# set this to 1 to stop query execution when an error occurs
export BIG_BENCH_STOP_AFTER_FAILURE="0"
